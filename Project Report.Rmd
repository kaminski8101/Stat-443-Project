---
title: "Gas Turbine CO and NOx Emission Analysis"
author: "Aayushi Gupta, Kyle Kaminski, Rosa Lin, Ruben Martinez"
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

The combined cycle power plant, also known as combined cycle gas turbine plant, is an assembly of heat engines that combine to generate electricity (Tüfekci). A combined-cycle power plant (CCPP) is made up of gas turbines, steam turbines, and heat recovery steam generators. The electricity is generated and combined in one cycle by gas and steam turbines and then transferred from one turbine to another.  

We are interested in identifying the process variables that impact carbon monoxide emissions. By determining the process variables that impact carbon monoxide emissions we will be able to find opportunities to reduce carbon monoxide emissions. 

### Gas Turbine CO and NOx Emission Data Set

The data comes from a gas turbine located in Turkey that studies the flue gas emissions of specifically carbon monoxide (CO) and nitrogen oxide (NOx) gases. The data set provides hourly statistics of 11 sensors. Data points were collected from a gas turbine from Jan 01 2011 to Dec 13 2015. 

## Description

The data file `gt_2015.csv` has 7384 observations and 11 variables from the UCI Gas Turbine CO and NOx Emission Data Set. We are going to explore and analyze the following variables: 

* `AT` - Ambient Temperature
* `AP` - Ambient Pressure
* `AH` -  Ambient Humidity
* `AFDP` - Air filter difference pressure 
* `GTEP` - Gas turbine exhaust pressure
* `TIT` - Turbine inlet temperature
* `TAT` - Turbine after temperature 
* `TEY` - Turbine energy yield 
* `CDP` - Compressor discharge pressure

Here’s a quick peek at the data set: 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(readr) 
gt_2015 <- read_csv("Project Data/gt_2015.csv")
gt_2015_typical <- gt_2015[gt_2015$TEY <= 136 & gt_2015$TEY >= 130,]
gt_2015_high <- gt_2015[gt_2015$TEY >= 160,]
knitr::kable(head(gt_2015)[,])
knitr::kable(head(gt_2015_typical)[,])
knitr::kable(head(gt_2015_high)[,])
```

Here's some descriptive statistics of the data set:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
summary(gt_2015)
summary(gt_2015_typical)
summary(gt_2015_high)
```


## Goals

The goal for this project is to utilize this data set for the purpose of studying flue gas emissions, specifically carbon monoxide(CO) and nitrogen oxides (NOx). Our focus will be to find statistically significant relationships between the ambient and turbine variables and the emissions variables. We will limit the size of our model to more clearly demonstrate these relationships. Ultimately we will suggest which variables make the biggest impact on emission levels in order to decrease emissions overall. 

# Exploratory Data Analysis 

Relationships between feature variables 

Figure 1: Scatterplot Matrices to decide which feature variables have a linear relationship 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
pairs(gt_2015, pch = 20, cex = 0.25)
pairs(gt_2015_typical, pch = 20, cex = 0.25)
pairs(gt_2015_high, pch = 20, cex = 0.25)

```

Figure 2: 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
knitr::kable(cor(gt_2015), digits = 2, caption = "Pairwise Correlation Between Variables (All Data)")
knitr::kable(cor(gt_201_typical), digits = 2, caption = "Pairwise Correlation Between Variables (Typical Energy Yield)")
knitr::kable(cor(gt_2015_high), digits = 2, caption = "Pairwise Correlation Between Variables (High Energy Yield)")
```

Remove variables that are highly correlated.

```{r, message=FALSE, echo=FALSE, warning=FALSE}
#vif 
library(faraway)
full_model_all     = lm(CO ~ . - NOX, data = gt_2015)
full_model_typical = lm(CO ~ . - NOX, data = gt_2015_typical)
full_model_high    = lm(CO ~ . - NOX, data = gt_2015_high)

vif(full_model_all    )
vif(full_model_typical)
vif(full_model_high   )

second_model_all     = lm(CO ~ . - NOX - TIT, data = gt_2015)
second_model_typical = lm(CO ~ . - NOX - TIT, data = gt_2015_typical)
second_model_high    = lm(CO ~ . - NOX - TEY, data = gt_2015_high)

vif(second_model_all    )
vif(second_model_typical)
vif(second_model_high   )

third_model_all     = lm(CO ~ . - NOX - TIT - CDP, data = gt_2015)
third_model_typical = lm(CO ~ . - NOX - TIT - AT, data = gt_2015_typical)
third_model_high    = lm(CO ~ . - NOX - TEY - CDP, data = gt_2015_high)

vif(third_model_all    )
vif(third_model_typical)
vif(third_model_high   )

initial_typical_linear_model <- third_model_typical
initial_high_linear_model    <- third_model_high

fourth_model_all     = lm(CO ~ . - NOX - TIT - CDP - TEY, data = gt_2015)

vif(fourth_model_all)

initial_all_linear_model <- fourth_model_all

```



Exploratory analysis shows possible linear relationships between the response variable CO and the feature variables CDP, TEY, TIT, GTEP and AFDP. Collinearity between some of the feature variables (TIT, CDP, and TEY) could cause some problems in our analysis and will likely lead to the removal of the redundant variables. 


# Methods

## Linear Regression

We will create a multiple linear regression model using all feature variables mentioned in the description of Section 1. The implementation and parameters of this model can be obtained by the following equation where we will find estimates for the parameters $\beta$ using: 

$$\hat \beta = (X^TX)^{-1}X^Ty$$

Key assumptions are stated as: 

* **L**inearity: can be written as a linear combination of the predictors.
* **I**ndependence: the errors are independent of each other (not highly correlated).
* **N**ormality: the distribution of the errors follow a normal distribution.
* **E**qual Variance: the error variance is the same.^[Dalpiaz David, Applied Statistics in R, https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html] 


We will then use model selection using backward BIC to tune our model and remove any insignificant predictor variables. This selection prefers smaller models which aligns with our goal of limiting the size of our final model. 


```{r}
full_model = lm(CO ~ ., data = gt_2015)
linear_model = lm(CO ~ .-NOX - TIT - CDP - TEY, data = gt_2015)
summary(linear_model)
#picking a new variable to test 
AT_model = lm(CO ~ AT, data = gt_2015)
AP_model = lm(CO ~ AP, data = gt_2015)
AH_model = lm(CO ~ AH, data = gt_2015)
AFDP_model = lm(CO ~ AFDP, data = gt_2015)
GTEP_model = lm(CO ~ GTEP, data = gt_2015)
TAT_model = lm(CO ~ TAT, data = gt_2015)
BIC(AT_model)
BIC(AP_model)
BIC(AH_model)
BIC(AFDP_model) #second best 
BIC(GTEP_model)
BIC(TAT_model)
BIC(linear_model) #this is the best model 

library(MASS)

n = length(resid(linear_model))
BIC_model = step(linear_model, direction = "backward", k = log(n))
coef(BIC_model)
stepAIC(linear_model, direction = "backward")

vector <- c(BIC(AT_model), BIC(AP_model), BIC(AH_model), BIC(AFDP_model), BIC(GTEP_model), BIC(TAT_model))

library(ggplot2)
df <- data.frame(vector = c(BIC(AT_model), BIC(AP_model), BIC(AH_model), BIC(AFDP_model), BIC(GTEP_model), BIC(TAT_model)), names = c ("AT", "AP", "AH", "AFDP", "GTEP", "TAT"))
ggplot(data = df, aes(x = names, y = vector), ylim = c(0, 50000)) + geom_bar(stat = "identity")
barplot(vector, main = "BIC values", xlab = "Variables",ylab = "Values", names.arg = c("AT", "AP", "AH", "AFDP", "GTEP", "TAT"), col = "gray", ylim = c(0, 45000))
```
## Linear and Lasso stepwise AIC Models
```{r}
library(caret)
#simplest linear model 
simple_linear_model <- lm(CO ~ . - TIT - CDP - TEY - NOX, data = gt_2015)

#5-fold cross validation
cv_5 <- trainControl(method = "cv", number = 5)

#AIC stepwise selected linear model 
linear_mod <- train(
          form = CO ~ . - TIT - CDP - TEY- NOX,
          data = gt_2015,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)

#Linear log model
linear_mod_2 <- train(
          form = log(CO) ~ . - TIT - CDP - TEY - NOX,
          data = gt_2015,
          method = "lmStepAIC",
          trControl = cv_5,
          nvmax = 10,
          trace = FALSE
)

#Lasso model
lasso_mod <- train(
          form = CO ~ . - TIT - CDP - TEY - NOX,
          data = gt_2015,
          method = "lasso",
          trControl = cv_5
)
```

##Linear Model Diagnostic Plots
```{r}

```


## Decision Trees
```{r load-packages-and-create-RMSE-function}
# install.packages('tree')
library(tidyverse)
library(tree)

RMSE <- function(y, y_hat) {
  rmse <- sqrt(sum(((y_hat - y)^2)/length(y)))
  print(rmse)
}
```
```{r train-and-test-split}
set.seed(1)
train <- gt_2015 %>% dplyr::select(-NOX) %>% sample_frac(0.8)
test <- gt_2015 %>% dplyr::select(-NOX) %>% setdiff(train)
```
```{r create-big-tree}
tree_CO <- tree(CO ~ . , train, 
                  control = tree.control(nobs = length(train$CO), 
                                         minsize = 2, mindev=0.001), method = "recursive.partition")
summary(tree_CO)
```
```{r plot-big-tree}
plot(tree_CO)
text(tree_CO, pretty = 0)
```
```{r use-tree-on-test-data-and-calculate-RMSE}
tree_pred <- predict(tree_CO, test)
RMSE(test$CO, tree_pred)
```
```{r plot-cross-validated-RMSE-against-terminal-node-size}
cv_info <- cv.tree(tree_CO, FUN = prune.tree) 
plot(cv_info$size, sqrt(cv_info$dev / nrow(train)), type = "b", xlab = "Number of Terminal Nodes", ylab = "RMSE", main = "Decision Tree Cross Validation")
```
```{r prune-tree-to-9-terminal-nodes}
pruned_tree <- prune.tree(tree_CO, best = 9)
summary(pruned_tree)
```
```{r plot-pruned-tree}
plot(pruned_tree)
text(pruned_tree, pretty = 0)
```
```{r calculate-pruned-tree-RMSE}
tree_pred <- predict(pruned_tree, test)
RMSE(test$CO, tree_pred)
```
```{r}
plot(tree_pred, test$CO, xlab = "Predicted", ylab = "Actual")
abline(0, 1)
```



```{r}
plot(gt_2015$CO, gt_2015$TEY, ylab = "Total Energy Yield", xlab = "Carbon Monoxide Output")
abline(v = 17, col = "red")
```
```{r}
data <- gt_2015 %>% mutate(Emissions = as.factor(ifelse(CO > 17, "High", "Low"))) %>% dplyr::select(-NOX)
high_CO <- data %>% filter(CO > 17) %>% dplyr::select(-CO)
low_CO <- data %>% dplyr::select(-CO) %>% setdiff(high_CO)

set.seed(1)
train <- bind_rows(low_CO %>% sample_frac(7/9), high_CO %>% sample_frac(7/9)) 
test <- data %>% dplyr::select(-CO) %>% setdiff(train)
```
```{r}
tree <- tree(Emissions ~ . , train, 
                  control = tree.control(nobs = length(train$Emissions), 
                                         minsize = 1))
summary(tree)
```
```{r}
plot(tree)
text(tree, pretty = 0)
```
```{r}
tree_pred <- predict(tree, train, type = "class")
table(predicted = tree_pred, actual = train$Emissions)

tree_pred <- predict(tree, test, type = "class")
table(predicted = tree_pred, actual = test$Emissions)
```



```{r}
set.seed(1)
# train <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% sample_frac(0.8)
# test <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% setdiff(train)
train <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% dplyr::select(-c(NOX, TEY, CO)) %>% sample_frac(0.8)
test <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% dplyr::select(-c(NOX, TEY, CO)) %>% setdiff(train)
```
```{r}
tree_Energy_CO_Ratio <- tree(Energy_CO_Ratio ~ . , train, 
                  control = tree.control(nobs = length(train$Energy_CO_Ratio), 
                                         minsize = 2, mindev=0.001), method = "recursive.partition")
summary(tree_Energy_CO_Ratio)
```
```{r}
plot(tree_Energy_CO_Ratio)
text(tree_Energy_CO_Ratio, pretty = 0)
```
```{r}
tree_pred <- predict(tree_Energy_CO_Ratio, test)
RMSE(test$Energy_CO_Ratio, tree_pred)
```
```{r}
cv_info <- cv.tree(tree_Energy_CO_Ratio, FUN = prune.tree) 
plot(cv_info$size, sqrt(cv_info$dev / nrow(train)), type = "b", xlab = "Number of Terminal Nodes", ylab = "RMSE", main = "Decision Tree Cross Validation")
```
```{r}
pruned_tree <- prune.tree(tree_Energy_CO_Ratio, best = 7)
summary(pruned_tree)
```
```{r}
plot(pruned_tree)
text(pruned_tree, pretty = 0)
```
```{r}
tree_pred <- predict(pruned_tree, test)
RMSE(test$Energy_CO_Ratio, tree_pred)
```
```{r}
plot(tree_pred, test$Energy_CO_Ratio, xlab = "Predicted", ylab = "Actual")
abline(0, 1)
```

