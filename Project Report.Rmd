---
title: "Gas Turbine CO Emission Analysis"
author: "Aayushi Gupta, Kyle Kaminski, Rosa Lin, Ruben Martinez"
date: ""
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction 

The combined cycle power plant, also known as combined cycle gas turbine plant, is an assembly of heat engines that combine to generate electricity (Tüfekci). A combined-cycle power plant (CCPP) is made up of gas turbines, steam turbines, and heat recovery steam generators. The electricity is generated and combined in one cycle by gas and steam turbines and then transferred from one turbine to another.  

We are interested in identifying the process variables that impact carbon monoxide emissions. By determining the process variables that impact carbon monoxide emissions we will be able to find opportunities to reduce carbon monoxide emissions. 

### Gas Turbine CO and NOx Emission Data Set

The data comes from a gas turbine located in Turkey that studies the flue gas emissions of specifically carbon monoxide (CO) and nitrogen oxide (NOx) gases. The data set provides hourly statistics of 11 sensors. Data points were collected from a gas turbine from Jan 01 2011 to Dec 13 2015. 

## Description

The data file `gt_2015.csv` has 7384 observations and 11 variables from the UCI Gas Turbine CO and NOx Emission Data Set. We are going to explore and analyze the following variables: 

* `AT` - Ambient Temperature
* `AP` - Ambient Pressure
* `AH` -  Ambient Humidity
* `AFDP` - Air Filter Difference Pressure 
* `GTEP` - Gas Turbine Exhaust Pressure
* `TIT` - Turbine Inlet Temperature
* `TAT` - Turbine After Temperature 
* `TEY` - Turbine Energy Yield 
* `CDP` - Compressor Discharge Pressure

Here’s a quick peek at the data set: 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(readr) 
gt_2015 <- read_csv("Project Data/gt_2015.csv")
gt_2015_typical <- gt_2015[gt_2015$TEY <= 133 & gt_2015$TEY >= 127,]
gt_2015_high <- gt_2015[gt_2015$TEY >= 160,]
knitr::kable(head(gt_2015)[,])
knitr::kable(head(gt_2015_typical)[,])
knitr::kable(head(gt_2015_high)[,])
```

Here's some descriptive statistics of the data set:

```{r, message=FALSE, echo=FALSE, warning=FALSE}
summary(gt_2015)
summary(gt_2015_typical)
summary(gt_2015_high)
```


## Goals

The goal for this project is to utilize this data set for the purpose of studying flue gas emissions, specifically carbon monoxide(CO) and nitrogen oxides (NOx). Our focus will be to find statistically significant relationships between the ambient and turbine variables and the emissions variables. We will limit the size of our model to more clearly demonstrate these relationships. Ultimately we will suggest which variables make the biggest impact on emission levels in order to decrease emissions overall. 

# Exploratory Data Analysis 

Relationships between feature variables 

Figure 1: Scatterplot Matrices to decide which feature variables have a linear relationship 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
pairs(gt_2015, pch = 20, cex = 0.25)
pairs(gt_2015_typical, pch = 20, cex = 0.25)
pairs(gt_2015_high, pch = 20, cex = 0.25)

```

Figure 2: 

```{r, message=FALSE, echo=FALSE, warning=FALSE}
knitr::kable(cor(gt_2015), digits = 2, caption = "Pairwise Correlation Between Variables (All Data)")
knitr::kable(cor(gt_2015_typical), digits = 2, caption = "Pairwise Correlation Between Variables (Typical Energy Yield)")
knitr::kable(cor(gt_2015_high), digits = 2, caption = "Pairwise Correlation Between Variables (High Energy Yield)")
```

Remove variables that are highly correlated.

```{r, message=FALSE, echo=FALSE, warning=FALSE}
#vif 
library(faraway)
full_model_all     = lm(CO ~ . - NOX, data = gt_2015)
full_model_typical = lm(CO ~ . - NOX, data = gt_2015_typical)
full_model_high    = lm(CO ~ . - NOX, data = gt_2015_high)

invisible(vif(full_model_all    ))
invisible(vif(full_model_typical))
invisible(vif(full_model_high   ))

second_model_all     = lm(CO ~ . - NOX - TIT, data = gt_2015)
second_model_typical = lm(CO ~ . - NOX - TIT, data = gt_2015_typical)
second_model_high    = lm(CO ~ . - NOX - TEY, data = gt_2015_high)

invisible(vif(second_model_all    ))
invisible(vif(second_model_typical))
invisible(vif(second_model_high   ))

third_model_all     = lm(CO ~ . - NOX - TIT - CDP, data = gt_2015)
third_model_typical = lm(CO ~ . - NOX - TIT - AT, data = gt_2015_typical)
third_model_high    = lm(CO ~ . - NOX - TEY - CDP, data = gt_2015_high)

invisible(vif(third_model_all    ))
invisible(vif(third_model_typical))
invisible(vif(third_model_high   ))

initial_typical_linear_model <- third_model_typical
initial_high_linear_model    <- third_model_high

fourth_model_all     = lm(CO ~ . - NOX - TIT - CDP - TEY, data = gt_2015)

invisible(vif(fourth_model_all))

initial_all_linear_model <- fourth_model_all

vif(initial_all_linear_model)
vif(initial_typical_linear_model)
vif(initial_high_linear_model)

```



Exploratory analysis shows possible linear relationships between the response variable CO and the feature variables CDP, TEY, TIT, GTEP and AFDP. Collinearity between some of the feature variables (TIT, CDP, and TEY) could cause some problems in our analysis and will likely lead to the removal of the redundant variables. 

#density 
```{r}
d <- density(gt_2015$TEY)
plot(d, xlab = "Turbine Energy Yield", ylab = "Density", main = "Turbnine Energy Yield Distribution")
polygon(d, col = "blue4", border = "chocolate1")
abline(v = c(127,133,160), lty = c(1,1,2), col = c("red","red","black"))
```

# Methods

## Linear Regression

We will create a multiple linear regression model using all feature variables mentioned in the description of Section 1. The implementation and parameters of this model can be obtained by the following equation where we will find estimates for the parameters $\beta$ using: 

$$\hat \beta = (X^TX)^{-1}X^Ty$$

Key assumptions are stated as: 

* **L**inearity: can be written as a linear combination of the predictors.
* **I**ndependence: the errors are independent of each other (not highly correlated).
* **N**ormality: the distribution of the errors follow a normal distribution.
* **E**qual Variance: the error variance is the same.^[Dalpiaz David, Applied Statistics in R, https://urldefense.com/v3/__https://daviddalpiaz.github.io/appliedstats/model-diagnostics.html__;!!DZ3fjg!pZQU6uJCClJrohh1D9pa0MjKMi32lYqIPLCJl_vX4wq1QtzWTjyE-7kqGzwyrgx2FQEo$ ] 


We will then use model selection using backward BIC to tune our model and remove any insignificant predictor variables. This selection prefers smaller models which aligns with our goal of limiting the size of our final model. 


```{r include=FALSE}
full_model = lm(CO ~ ., data = gt_2015)
linear_model = lm(CO ~ .-NOX - TIT - CDP - TEY, data = gt_2015)
summary(linear_model)
#picking a new variable to test 
AT_model = lm(CO ~ AT, data = gt_2015)
AP_model = lm(CO ~ AP, data = gt_2015)
AH_model = lm(CO ~ AH, data = gt_2015)
AFDP_model = lm(CO ~ AFDP, data = gt_2015)
GTEP_model = lm(CO ~ GTEP, data = gt_2015)
TAT_model = lm(CO ~ TAT, data = gt_2015)
BIC(AT_model)
BIC(AP_model)
BIC(AH_model)
BIC(AFDP_model) #second best 
BIC(GTEP_model)
BIC(TAT_model)
BIC(linear_model) #this is the best model 

library(MASS)

n = length(resid(linear_model))
BIC_model = step(linear_model, direction = "backward", k = log(n))
coef(BIC_model)
stepAIC(linear_model, direction = "backward")

vector <- c(BIC(AT_model), BIC(AP_model), BIC(AH_model), BIC(AFDP_model), BIC(GTEP_model), BIC(TAT_model))

library(ggplot2)
df <- data.frame(vector = c(BIC(AT_model), BIC(AP_model), BIC(AH_model), BIC(AFDP_model), BIC(GTEP_model), BIC(TAT_model)), names = c ("AT", "AP", "AH", "AFDP", "GTEP", "TAT"))
ggplot(data = df, aes(x = names, y = vector), ylim = c(0, 50000)) + geom_bar(stat = "identity")
barplot(vector, main = "BIC values", xlab = "Variables",ylab = "Values", names.arg = c("AT", "AP", "AH", "AFDP", "GTEP", "TAT"), col = "gray", ylim = c(0, 45000))
```


## Linear and Lasso stepwise AIC Models
```{r include=FALSE}
library(caret)
#5-fold cross validation
cv_5 <- trainControl(method = "cv", number = 5)
```


#All Data
```{r include=FALSE}
set.seed(10)
#AIC stepwise selected linear model 
all_linear_mod <- train(
          form = CO ~ . - NOX - TIT - CDP - TEY ,
          data = gt_2015,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
all_linear_mod_lm <- lm(CO ~ AT + AH + AFDP + GTEP + TAT, data = gt_2015)


#Lasso model
all_lasso_mod <- train(
          form = CO ~ . - NOX - TIT - CDP - TEY ,
          data = gt_2015,
          method = "lasso",
          trControl = cv_5
)
```

#Typical Energy Yield (130-136)
```{r include=FALSE}
set.seed(10)
#AIC stepwise selected linear model 
typical_linear_mod <- train(
          form = CO ~ . - NOX - TIT - AT,
          data = gt_2015_typical,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
typical_linear_mod_lm <- lm(CO ~ AP + AH + AFDP + GTEP + TAT + TEY + CDP, data = gt_2015_typical)


#Lasso model
typical_lasso_mod <- train(
          form = CO ~ . - NOX - TIT - AT,
          data = gt_2015_typical,
          method = "lasso",
          trControl = cv_5
)
```

#High Energy Yield (160+)
```{r include=FALSE}
set.seed(10)

#AIC stepwise selected linear model 
high_linear_mod <- train(
          form = CO ~ . - NOX - TEY - CDP,
          data = gt_2015_high,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
high_linear_mod_lm <- lm(CO ~ AT + AFDP + GTEP + TIT + TAT, data =  gt_2015_high)


#Lasso model
high_lasso_mod <- train(
          form = CO ~ . - NOX - TEY - CDP,
          data = gt_2015_high,
          method = "lasso",
          trControl = cv_5
)
```


#Box-Cox Lambdas
```{r}
all_lambda <- boxcox(all_linear_mod_lm, plotit = FALSE)$x[which.max(boxcox(all_linear_mod_lm, plotit = FALSE)$y)]
typical_lambda <- boxcox(typical_linear_mod_lm, plotit = FALSE)$x[which.max(boxcox(typical_linear_mod_lm, plotit = FALSE)$y)]
high_lambda <- boxcox(high_linear_mod_lm, plotit = FALSE)$x[which.max(boxcox(high_linear_mod_lm, plotit = FALSE)$y)]
```

#Box-Cox Transformed Models
```{r}
#All Data Box-Cox Transformed Linear Model
set.seed(10)
all_bc_linear_mod <- train(
          form = CO^(.1) ~ . - NOX  - TIT - CDP - TEY ,
          data = gt_2015,
          method = "lmStepAIC",
          trControl = cv_5,
          nvmax = 10,
          trace = FALSE
)
all_bc_linear_mod_lm <- lm(CO^(.1) ~ AT + AP + AH + AFDP + GTEP + TAT, data = gt_2015)
plot(all_bc_linear_mod$finalModel)

#Typical Data Box-Cox Transformed Linear Model
typical_bc_linear_mod <- train(
          form = CO^(-.1) ~ . - NOX - TIT - AT,
          data = gt_2015_typical,
          method = "lmStepAIC",
          trControl = cv_5,
          nvmax = 10,
          trace = FALSE
)
typical_bc_linear_mod_lm <- lm(CO^(-.1) ~ AP + AH + AFDP + GTEP + TAT + TEY + CDP, data = gt_2015_typical)
plot(typical_bc_linear_mod$finalModel)

#High Data Box-Cox Transformed Linear Model
high_bc_linear_mod <- train(
          form = CO^(1.9) ~ . - NOX - TEY - CDP,
          data = gt_2015_high,
          method = "lmStepAIC",
          trControl = cv_5,
          nvmax = 10,
          trace = FALSE
)
high_bc_linear_mod_lm <- lm(CO^(1.9) ~ AT + AFDP + GTEP + TIT + TAT, data =  gt_2015_high)
plot(typical_bc_linear_mod$finalModel)
```


#Results
```{r }
all_linear_mod$results
all_bc_linear_mod$results
all_lasso_mod$results

typical_linear_mod$results
typical_bc_linear_mod$results
typical_lasso_mod$results

high_linear_mod$results
high_bc_linear_mod$results
all_lasso_mod$results

typical_linear_mod$results
typical_lasso_mod$results

high_linear_mod$results
high_lasso_mod$results
```

#plots
```{r }
plot(all_linear_mod$finalModel)
plot(all_bc_linear_mod$finalModel)
#plot(all_lasso_mod$finalModel)

plot(typical_linear_mod$finalModel)
plot(typical_bc_linear_mod$finalModel)
#plot(typical_lasso_mod$finalModel)

plot(high_linear_mod$finalModel)
plot(high_bc_linear_mod$finalModel)
#plot(all_lasso_mod$finalModel)

plot(typical_linear_mod$finalModel)
#plot(typical_lasso_mod$finalModel)

plot(high_linear_mod$finalModel)
#plot(high_lasso_mod$finalModel)
```

#Outlier Search
```{r}

plot(cooks.distance(all_linear_mod$finalModel))
plot(cooks.distance(all_bc_linear_mod$finalModel))


plot(cooks.distance(typical_linear_mod$finalModel))
plot(cooks.distance(typical_bc_linear_mod$finalModel))


plot(cooks.distance(high_linear_mod$finalModel))
plot(cooks.distance(high_bc_linear_mod$finalModel))



which(cooks.distance(all_linear_mod$finalModel) > .05)
which(cooks.distance(all_bc_linear_mod$finalModel) > .04)


which(cooks.distance(typical_linear_mod$finalModel) > .05)
which(cooks.distance(typical_bc_linear_mod$finalModel) > .04)


which(cooks.distance(high_linear_mod$finalModel) > .05)
which(cooks.distance(high_bc_linear_mod$finalModel) >.04)




which(cooks.distance(all_linear_mod$finalModel) > 4/nrow(gt_2015))
which(cooks.distance(all_bc_linear_mod$finalModel) > 4/nrow(gt_2015))


which(cooks.distance(typical_linear_mod$finalModel) > 4/nrow(gt_2015_typical))
which(cooks.distance(typical_bc_linear_mod$finalModel) > 4/nrow(gt_2015_typical))


which(cooks.distance(high_linear_mod$finalModel) > 4/nrow(gt_2015_high))
which(cooks.distance(high_bc_linear_mod$finalModel) > 4/nrow(gt_2015_high))
```

#Outlier Removal
```{r}
outlier_removed_gt_2015 <- gt_2015[which(cooks.distance(all_linear_mod$finalModel) < .05),]
outlier_removed_gt_2015_typical <- gt_2015[which(cooks.distance(typical_linear_mod$finalModel) < .05),]
outlier_removed_gt_2015_high <- gt_2015[which(cooks.distance(high_linear_mod$finalModel) < .05),]
```

#Refitting Models
```{r}
or_full_model_all     = lm(CO ~ . - NOX, data = outlier_removed_gt_2015)
or_full_model_typical = lm(CO ~ . - NOX, data = outlier_removed_gt_2015_typical)
or_full_model_high    = lm(CO ~ . - NOX, data = outlier_removed_gt_2015_high)

(vif(or_full_model_all    ))
(vif(or_full_model_typical))
(vif(or_full_model_high   ))

or_second_model_all     = lm(CO ~ . - NOX - TIT, data = outlier_removed_gt_2015)
or_second_model_typical = lm(CO ~ . - NOX - TIT, data = outlier_removed_gt_2015_typical)
or_second_model_high    = lm(CO ~ . - NOX - CDP, data = outlier_removed_gt_2015_high)

(vif(or_second_model_all    ))
(vif(or_second_model_typical))
(vif(or_second_model_high   ))

or_third_model_all     = lm(CO ~ . - NOX - TIT - CDP, data = outlier_removed_gt_2015)
or_third_model_typical = lm(CO ~ . - NOX - TIT - CDP, data = outlier_removed_gt_2015_typical)
or_third_model_high    = lm(CO ~ . - NOX - CDP - TEY, data = outlier_removed_gt_2015_high)

(vif(or_third_model_all    ))
(vif(or_third_model_typical))
(vif(or_third_model_high   ))

or_fourth_model_all     = lm(CO ~ . - NOX - TIT - CDP - TEY, data = outlier_removed_gt_2015)
or_fourth_model_typical = lm(CO ~ . - NOX - TIT - CDP - AFDP, data = outlier_removed_gt_2015_typical)
or_fourth_model_high    = lm(CO ~ . - NOX - CDP - TEY - AFDP, data = outlier_removed_gt_2015_high)

(vif(or_fourth_model_all    ))
(vif(or_fourth_model_typical))
(vif(or_fourth_model_high   ))

or_initial_model_all <- lm(CO ~ . - NOX - TIT - CDP - TEY, data = outlier_removed_gt_2015)

or_fifth_model_typical = lm(CO ~ . - NOX - TIT - CDP - AFDP - GTEP, data = outlier_removed_gt_2015_typical)
or_fifth_model_high    = lm(CO ~ . - NOX - CDP - TEY - AFDP - GTEP, data = outlier_removed_gt_2015_high)

(vif(or_fifth_model_typical))
(vif(or_fifth_model_high   ))

or_initial_model_typical = lm(CO ~ . - NOX - TIT - CDP - AFDP - GTEP, data = outlier_removed_gt_2015_typical)
or_initial_model_high    = lm(CO ~ . - NOX - CDP - TEY - AFDP - GTEP, data = outlier_removed_gt_2015_high)
```

```{r}
set.seed(10)
#AIC stepwise selected linear model 
or_all_linear_mod <- train(
          form = CO ~ . - NOX - TIT - CDP - TEY ,
          data = outlier_removed_gt_2015,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
or_all_linear_mod_lm <- lm(CO ~ AT + AP + AH + AFDP + GTEP + TAT, data = gt_2015)


#AIC stepwise selected linear model 
or_typical_linear_mod <- train(
          form = CO ~ . - NOX - TIT - CDP - AFDP - GTEP,
          data = outlier_removed_gt_2015_typical,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
or_typical_linear_mod_lm <- lm(CO ~ AT + AP + AH + TAT + TEY, data = gt_2015)


#AIC stepwise selected linear model 
or_high_linear_mod <- train(
          form = CO ~ . - NOX - CDP - TEY - AFDP - GTEP,
          data = outlier_removed_gt_2015_high,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
or_high_linear_mod_lm <- lm(CO ~ AT + AP + AH + TIT + TAT, data = gt_2015)
```

```{r}
plot(or_all_linear_mod$finalModel)
plot(or_typical_linear_mod$finalModel)
plot(or_high_linear_mod$finalModel)
```

#Outlier Removed Box-Cox Lambdas
```{r}
or_all_lambda <- boxcox(or_all_linear_mod_lm, plotit = FALSE)$x[which.max(boxcox(or_all_linear_mod_lm, plotit = FALSE)$y)]
or_typical_lambda <- boxcox(or_typical_linear_mod_lm, plotit = FALSE)$x[which.max(boxcox(or_typical_linear_mod_lm, plotit = FALSE)$y)]
or_high_lambda <- boxcox(or_high_linear_mod_lm, plotit = FALSE)$x[which.max(boxcox(or_high_linear_mod_lm, plotit = FALSE)$y)]
```

#Outlier Removed Box-Cox Transformed Models
```{r}
#All Data Box-Cox Transformed Linear Model
set.seed(10)
or_all_bc_linear_mod <- train(
          form = CO^(.1) ~ . - NOX - TIT - CDP - TEY ,
          data = outlier_removed_gt_2015,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
or_all_bc_linear_mod_lm <- lm(CO ~ AT + AP + AH + AFDP + GTEP + TAT, data = outlier_removed_gt_2015)


#AIC stepwise selected linear model 
or_typical_bc_linear_mod <- train(
          form = CO^(.2) ~ . - NOX - TIT - CDP - AFDP - GTEP,
          data = outlier_removed_gt_2015_typical,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
or_bc_typical_linear_mod_lm <- lm(CO ~AT + AP + TAT + TEY, data = outlier_removed_gt_2015_typical)


#AIC stepwise selected linear model 
or_high_bc_linear_mod <- train(
          form = CO^(.2) ~ . - NOX - CDP - TEY - AFDP - GTEP,
          data = outlier_removed_gt_2015_high,
          method = "lmStepAIC",
          trControl = cv_5,
          trace = FALSE
)
or_high_bc_linear_mod_lm <- lm(CO ~ AT + AP + TIT + TAT, data = outlier_removed_gt_2015_high)
```

```{r}
plot(or_all_bc_linear_mod$finalModel)
plot(or_typical_bc_linear_mod$finalModel)
plot(or_high_bc_linear_mod$finalModel)
```

##Linear Model Diagnostic Plots
```{r}
# plot(cooks.distance(all_linear_mod$finalModel))
# plot(cooks.distance(typical_linear_mod$finalModel))
# plot(cooks.distance(high_linear_mod$finalModel))
# 
# 
# which(cooks.distance(all_linear_mod$finalModel) > .05)
# which(cooks.distance(typical_linear_mod$finalModel) > .05)
# which(cooks.distance(high_linear_mod$finalModel) > .05)
# 
# 
# which(cooks.distance(all_linear_mod$finalModel) > 4/nrow(gt_2015))
# which(cooks.distance(typical_linear_mod$finalModel) > 4/nrow(gt_2015_typical))
# which(cooks.distance(high_linear_mod$finalModel) > 4/nrow(gt_2015_high))


plot(cooks.distance(all_bc_linear_mod$finalModel))
plot(cooks.distance(typical_bc_linear_mod$finalModel))
plot(cooks.distance(high_bc_linear_mod$finalModel))


which(cooks.distance(all_bc_linear_mod$finalModel) > .05)
which(cooks.distance(typical_bc_linear_mod$finalModel) > .05)
which(cooks.distance(high_bc_linear_mod$finalModel) > .05)


which(cooks.distance(all_bc_linear_mod$finalModel) > 4/nrow(gt_2015))
which(cooks.distance(typical_bc_linear_mod$finalModel) > 4/nrow(gt_2015_typical))
which(cooks.distance(high_bc_linear_mod$finalModel) > 4/nrow(gt_2015_high))
```


## Decision Trees
#All Data
```{r load-packages-and-create-RMSE-function}
# install.packages('tree')
library(tidyverse)
library(tree)

RMSE <- function(y, y_hat) {
  rmse <- sqrt(sum(((y_hat - y)^2)/length(y)))
  print(rmse)
}
```
```{r train-and-test-split}
set.seed(10)
train <- gt_2015 %>% dplyr::select(-NOX) %>% sample_frac(0.8)
test <- gt_2015 %>% dplyr::select(-NOX) %>% setdiff(train)
```
```{r create-big-tree}
tree_CO <- tree(CO ~ . , train, 
                  control = tree.control(nobs = length(train$CO), 
                                         minsize = 4, mindev=0.001), method = "recursive.partition")
summary(tree_CO)
```
```{r plot-big-tree}
plot(tree_CO)
text(tree_CO, pretty = 0)
```
```{r use-tree-on-test-data-and-calculate-RMSE}
tree_pred <- predict(tree_CO, test)
RMSE(test$CO, tree_pred)
```
```{r plot-cross-validated-RMSE-against-terminal-node-size}
cv_info <- cv.tree(tree_CO, FUN = prune.tree) 
plot(cv_info$size, sqrt(cv_info$dev / nrow(train)), type = "b", xlab = "Number of Terminal Nodes", ylab = "RMSE", main = "Decision Tree Cross Validation")
```
```{r prune-tree-to-11-terminal-nodes}
pruned_tree <- prune.tree(tree_CO, best = 11)
summary(pruned_tree)
```
```{r plot-pruned-tree}
plot(pruned_tree)
text(pruned_tree, pretty = 0)
```
```{r calculate-pruned-tree-RMSE}
tree_pred <- predict(pruned_tree, test)
RMSE(test$CO, tree_pred)
```
```{r}
plot(tree_pred, test$CO, xlab = "Predicted", ylab = "Actual")
abline(0, 1)
```


#Typical Energy Yield (127-133)
```{r}
set.seed(10)
train_typical <- gt_2015_typical %>% dplyr::select(-NOX) %>% sample_frac(0.8)
test_typical <- gt_2015_typical %>% dplyr::select(-NOX) %>% setdiff(train_typical)
```
```{r}
tree_CO_typical <- tree(CO ~ . , train_typical,
                        control = tree.control(nobs = length(train_typical$CO), 
                                         minsize = 2, mindev=0.001), method = "recursive.partition")
summary(tree_CO_typical)
```
```{r}
plot(tree_CO_typical)
text(tree_CO_typical, pretty = 0)
```
```{r}
tree_pred_typical <- predict(tree_CO_typical, test_typical)
RMSE(test_typical$CO, tree_pred_typical)
```
```{r}
cv_info_typical <- cv.tree(tree_CO_typical, FUN = prune.tree) 
plot(cv_info_typical$size, sqrt(cv_info_typical$dev / nrow(train_typical)), type = "b", xlab = "Number of Terminal Nodes", ylab = "RMSE", main = "Decision Tree Cross Validation")
```
```{r}
pruned_tree_typical <- prune.tree(tree_CO_typical, best = 5)
summary(pruned_tree_typical)
```
```{r}
plot(pruned_tree_typical)
text(pruned_tree_typical, pretty = 0)
```
```{r}
tree_pred_typical <- predict(pruned_tree_typical, test_typical)
RMSE(test_typical$CO, tree_pred_typical)
```
```{r}
plot(tree_pred_typical, test_typical$CO, xlab = "Predicted", ylab = "Actual")
abline(0, 1)
```


#High Energy Yield (160+)
```{r train-and-test-split-high}
set.seed(10)
train_high <- gt_2015_high %>% dplyr::select(-NOX) %>% sample_frac(0.8)
test_high <- gt_2015_high %>% dplyr::select(-NOX) %>% setdiff(train_high)
```
```{r create-big-tree-high}
tree_CO_high <- tree(CO ~ . , train_high,
                     control = tree.control(nobs = length(train_high$CO), 
                                         minsize = 2, mindev=0.001), method = "recursive.partition")
summary(tree_CO_high)
```
```{r plot-big-tree-high}
plot(tree_CO_high)
text(tree_CO_high, pretty = 0)
```
```{r use-tree-on-test-data-and-calculate-RMSE-high}
tree_pred_high <- predict(tree_CO_high, test_high)
RMSE(test_high$CO, tree_pred_high)
```
```{r plot-cross-validated-RMSE-against-terminal-node-size-high}
cv_info_high <- cv.tree(tree_CO_high, FUN = prune.tree) 
plot(cv_info_high$size, sqrt(cv_info_high$dev / nrow(train_high)), type = "b", xlab = "Number of Terminal Nodes", ylab = "RMSE", main = "Decision Tree Cross Validation")
```
```{r prune-tree-to-6-terminal-nodes-high}
pruned_tree_high <- prune.tree(tree_CO_high, best = 6)
summary(pruned_tree_high)
```
```{r plot-pruned-tree-high}
plot(pruned_tree_high)
text(pruned_tree_high, pretty = 0)
```
```{r calculate-pruned-tree-RMSE-high}
tree_pred_high <- predict(pruned_tree_high, test_high)
RMSE(test_high$CO, tree_pred_high)
```
```{r}
plot(tree_pred_high, test_high$CO, xlab = "Predicted", ylab = "Actual")
abline(0, 1)
```








# Tree predicting high vs. low carbon monoxide output
```{r}
plot(gt_2015$CO, gt_2015$TEY, ylab = "Total Energy Yield", xlab = "Carbon Monoxide Output")
abline(v = 17, col = "red")
```
```{r}
data <- gt_2015 %>% mutate(Emissions = as.factor(ifelse(CO > 17, "High", "Low"))) %>% dplyr::select(-NOX)
high_CO <- data %>% filter(CO > 17) %>% dplyr::select(-CO)
low_CO <- data %>% dplyr::select(-CO) %>% setdiff(high_CO)

set.seed(10)
train <- bind_rows(low_CO %>% sample_frac(7/9), high_CO %>% sample_frac(7/9)) 
test <- data %>% dplyr::select(-CO) %>% setdiff(train)
```
```{r}
tree <- tree(Emissions ~ . , train, 
                  control = tree.control(nobs = length(train$Emissions), 
                                         minsize = 1))
summary(tree)
```
```{r}
plot(tree)
text(tree, pretty = 0)
```
```{r}
tree_pred <- predict(tree, train, type = "class")
table(predicted = tree_pred, actual = train$Emissions)

tree_pred <- predict(tree, test, type = "class")
table(predicted = tree_pred, actual = test$Emissions)
```


# Tree predicting ratio of energy yield over carbon monoxide
```{r}
set.seed(10)
# train <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% sample_frac(0.8)
# test <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% setdiff(train)
train <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% dplyr::select(-c(NOX, TEY, CO)) %>% sample_frac(0.8)
test <- gt_2015 %>% mutate(Energy_CO_Ratio = TEY / CO) %>% dplyr::select(-c(NOX, TEY, CO)) %>% setdiff(train)
```
```{r}
tree_Energy_CO_Ratio <- tree(Energy_CO_Ratio ~ . , train, 
                  control = tree.control(nobs = length(train$Energy_CO_Ratio), 
                                         minsize = 2, mindev=0.001), method = "recursive.partition")
summary(tree_Energy_CO_Ratio)
```
```{r}
plot(tree_Energy_CO_Ratio)
text(tree_Energy_CO_Ratio, pretty = 0)
```
```{r}
tree_pred <- predict(tree_Energy_CO_Ratio, test)
RMSE(test$Energy_CO_Ratio, tree_pred)
```
```{r}
cv_info <- cv.tree(tree_Energy_CO_Ratio, FUN = prune.tree) 
plot(cv_info$size, sqrt(cv_info$dev / nrow(train)), type = "b", xlab = "Number of Terminal Nodes", ylab = "RMSE", main = "Decision Tree Cross Validation")
```
```{r}
pruned_tree <- prune.tree(tree_Energy_CO_Ratio, best = 7)
summary(pruned_tree)
```
```{r}
plot(pruned_tree)
text(pruned_tree, pretty = 0)
```
```{r}
tree_pred <- predict(pruned_tree, test)
RMSE(test$Energy_CO_Ratio, tree_pred)
```
```{r}
plot(tree_pred, test$Energy_CO_Ratio, xlab = "Predicted", ylab = "Actual")
abline(0, 1)
```

